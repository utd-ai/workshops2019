{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание по теме \"Постановка задачи\" (часть 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель этого задания - привлечь внимание к одному из важных шагов постановки задачи машинного обучения: выбору метрики. Для этого предлагается изучить, как модель может меняться в зависимости от оптимизируемой метрики качества. Лучше всего это заметно на примере простых моделей, поэтому мы начнем с решения задачи регрессии с помощью константного прогноза. \n",
    "\n",
    "Затем мы рассмотрим задачу классификации с несбалансированными классами и изучим значения различных метрик для одной и той же прогнозной модели, а после этого - решения, которые получаются при оптимизации различных метрик качества по гиперпараметрам прогнозной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допишите код там, где это требуется (отмечено комментариями # TODO) и ответьте на вопросы, приведенные в этом блокноте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим синтетические данные с выбросами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = np.random.RandomState(42)\n",
    "data = 1 + np.concatenate((\n",
    "    np.abs(gen.normal(loc=0., scale=100, size=10000)), # основные данные\n",
    "    np.abs(30000 * gen.standard_cauchy(size=10)) # небольшая часть выбросов\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите реализацию метрик регрессии (попробуйте не использовать sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(answers, predictions):\n",
    "    # TODO допишите реализацию\n",
    "    \n",
    "\n",
    "def rmse(answers, predictions):\n",
    "    # TODO допишите реализацию\n",
    "    \n",
    "\n",
    "def mape(answers, predictions):\n",
    "    # TODO допишите реализацию\n",
    "    \n",
    "\n",
    "def smape(answers, predictions):\n",
    "    # TODO допишите реализацию\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем зависимость качества от константы, которой мы будем предсказывать целевые переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x_coords, y_coords):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.ylim(np.min(y_coords), np.max(y_coords))\n",
    "    plt.xlim(np.min(x_coords), np.max(x_coords))\n",
    "    plt.plot(x_coords, y_coords)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coords = list(range(0, 250, 5)) # диапазон значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_coords, [mae(data, x) for x in x_coords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_coords, [rmse(data, x) for x in x_coords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_coords, [mape(data, x) for x in x_coords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_coords, [smape(data, x) for x in x_coords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объясните наблюдаемые эффекты для каждого графика:\n",
    "* Почему кривая имеет такую форму?\n",
    "* Где её точный оптимум (возможно, придётся написать дополительный код)?\n",
    "* Какие выводы можно сделать с точки зрения использования метрики для оценки алгоритма?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: получите и выведите на экран оптимальные значения метрик\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: напишите выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики классификации при дисбалансе классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся sklearn реализацией метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём стандартный датасет для классификации из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем алгоритм для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators=1000, random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "points = list(range(1, 101))\n",
    "\n",
    "for k in points:\n",
    "    # TODO постройте список индексов, такой, чтобы каждый \n",
    "    # индекс объекта с ответом 0 попал в тест один раз, \n",
    "    # а каждый индекс объекта с ответом 1 попал в тест k раз\n",
    "    # (создаем дисбалланс классов в тесте)\n",
    "    indices = \n",
    "    \n",
    "    X = X_test[indices, :]\n",
    "    y = y_test[indices]\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    accuracy_scores.append(accuracy_score(y, y_pred))\n",
    "    recall_scores.append(recall_score(y, y_pred))\n",
    "    precision_scores.append(precision_score(y, y_pred))\n",
    "    f1_scores.append(f1_score(y, y_pred))\n",
    "    roc_auc_scores.append(roc_auc_score(y, y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим кривые в зависимости от $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(points, accuracy_scores)\n",
    "plt.plot(points, recall_scores)\n",
    "plt.plot(points, precision_scores)\n",
    "plt.plot(points, f1_scores)\n",
    "plt.plot(points, roc_auc_scores)\n",
    "plt.grid()\n",
    "plt.legend([\n",
    "    'accuracy_scores',\n",
    "    'recall_scores',\n",
    "    'precision_scores',\n",
    "    'f1_scores',\n",
    "    'roc_auc_scores'\n",
    "], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Почему кривые такие? Почему некоторые не меняются, а некоторые меняются\n",
    "* Почему у кривых такие асимптотические значения? Почему у некоторых они совпадают?\n",
    "* Какие выводы можно сделать с точки зрения использования метрики для оценки алгоритма?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: напишите выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимальные гиперпараметры при обучении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_algo(algo):\n",
    "    print(algo.best_params_)\n",
    "    print('Train:')\n",
    "    y_pred = algo.predict(X_train)\n",
    "    print('\\taccuracy_score', accuracy_score(y_train, y_pred))\n",
    "    print('\\trecall_score', recall_score(y_train, y_pred))\n",
    "    print('\\tprecision_score', precision_score(y_train, y_pred))\n",
    "    print('\\tf1_score', f1_score(y_train, y_pred))\n",
    "    print('\\troc_auc_score', roc_auc_score(y_train, y_pred))\n",
    "    print('Test:')\n",
    "    y_pred = algo.predict(X_test)\n",
    "    print('\\taccuracy_score', accuracy_score(y_test, y_pred))\n",
    "    print('\\trecall_score', recall_score(y_test, y_pred))\n",
    "    print('\\tprecision_score', precision_score(y_test, y_pred))\n",
    "    print('\\tf1_score', f1_score(y_test, y_pred))\n",
    "    print('\\troc_auc_score', roc_auc_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже будут перебираться гиперпараметры и находиться оптимальный алгоритм. Почему получаются именно такие гиперпараметры?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy optimal')\n",
    "estimate_algo(GridSearchCV(\n",
    "    XGBClassifier(random_state=42), \n",
    "    param_grid=dict(\n",
    "        n_estimators=[5, 10, 20, 25],\n",
    "        max_depth=[1, 2, 3, 4, 5, 6, 7],\n",
    "        learning_rate=[0.1, 0.2, 0.05, 0.3, 0.4]\n",
    "    ),\n",
    "    cv=2, scoring=make_scorer(accuracy_score), iid=False\n",
    ").fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('recall optimal')\n",
    "estimate_algo(GridSearchCV(\n",
    "    XGBClassifier(random_state=42), \n",
    "    param_grid=dict(\n",
    "        n_estimators=[5, 10, 20, 25],\n",
    "        max_depth=[1, 2, 3, 4, 5, 6, 7],\n",
    "        learning_rate=[0.1, 0.2, 0.05, 0.3, 0.4]\n",
    "    ),\n",
    "    cv=2, scoring=make_scorer(recall_score), iid=False\n",
    ").fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision optimal')\n",
    "estimate_algo(GridSearchCV(\n",
    "    XGBClassifier(random_state=42), \n",
    "    param_grid=dict(\n",
    "        n_estimators=[5, 10, 20, 25],\n",
    "        max_depth=[1, 2, 3, 4, 5, 6, 7],\n",
    "        learning_rate=[0.1, 0.2, 0.05, 0.3, 0.4]\n",
    "    ),\n",
    "    cv=2, scoring=make_scorer(precision_score), iid=False\n",
    ").fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('roc_auc optimal')\n",
    "estimate_algo(GridSearchCV(\n",
    "    XGBClassifier(random_state=42), \n",
    "    param_grid=dict(\n",
    "        n_estimators=[5, 10, 20, 25],\n",
    "        max_depth=[1, 2, 3, 4, 5, 6, 7],\n",
    "        learning_rate=[0.1, 0.2, 0.05, 0.3, 0.4]\n",
    "    ),\n",
    "    cv=2, scoring=make_scorer(roc_auc_score), iid=False\n",
    ").fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: напишите выводы"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
